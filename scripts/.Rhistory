xmldata <- simplified %>%
filter(sample_type==a) %>%
filter(guppied_date=="t2") %>%
group_split(component)
t2 +
xlab(paste0("PC3 (",get_var(find_PC3(xmldata)),"%)"))+
ylab(paste0("PC4 (",get_var(find_PC4(xmldata)),"%)"))
# PC3
grid.text(PC_down(find_PC3(xmldata)), x = unit(0.3, "npc"),
y = unit(0.1, "npc"),
gp = gpar(fontsize = 5))
grid.text(PC_up(find_PC3(xmldata)), x = unit(0.85, "npc"),
y = unit(0.1, "npc"),
gp = gpar(fontsize = 5))
# PC4
grid.text(PC_down(find_PC4(xmldata)), x = unit(0.1, "npc"),
y = unit(0.25, "npc"),
gp = gpar(fontsize = 5))
grid.text(PC_up(find_PC4(xmldata)), x = unit(0.1, "npc"),
y = unit(0.8, "npc"),
gp = gpar(fontsize = 5))
###############################
t4 <- PC3PC4_plots$plots[[3]]
xmldata <- simplified %>%
filter(sample_type==a) %>%
filter(guppied_date=="t4") %>%
group_split(component)
t4 +
xlab(paste0("PC3 (",get_var(find_PC3(xmldata)),"%)"))+
ylab(paste0("PC4 (",get_var(find_PC4(xmldata)),"%)"))
# PC3
grid.text(PC_down(find_PC3(xmldata)), x = unit(0.3, "npc"),
y = unit(0.1, "npc"),
gp = gpar(fontsize = 5))
grid.text(PC_up(find_PC3(xmldata)), x = unit(0.85, "npc"),
y = unit(0.1, "npc"),
gp = gpar(fontsize = 5))
# PC4
grid.text(PC_down(find_PC4(xmldata)), x = unit(0.1, "npc"),
y = unit(0.25, "npc"),
gp = gpar(fontsize = 5))
grid.text(PC_up(find_PC4(xmldata)), x = unit(0.1, "npc"),
y = unit(0.8, "npc"),
gp = gpar(fontsize = 5))
###############################
t6 <- PC3PC4_plots$plots[[4]]
xmldata <- simplified %>%
filter(sample_type==a) %>%
filter(guppied_date=="t6") %>%
group_split(component)
t6 +
xlab(paste0("PC3 (",get_var(find_PC3(xmldata)),"%)"))+
ylab(paste0("PC4 (",get_var(find_PC4(xmldata)),"%)"))
# PC3
grid.text(PC_down(find_PC3(xmldata)), x = unit(0.3, "npc"),
y = unit(0.1, "npc"),
gp = gpar(fontsize = 5))
grid.text(PC_up(find_PC3(xmldata)), x = unit(0.85, "npc"),
y = unit(0.1, "npc"),
gp = gpar(fontsize = 5))
# PC4
grid.text(PC_down(find_PC4(xmldata)), x = unit(0.1, "npc"),
y = unit(0.25, "npc"),
gp = gpar(fontsize = 5))
grid.text(PC_up(find_PC4(xmldata)), x = unit(0.1, "npc"),
y = unit(0.8, "npc"),
gp = gpar(fontsize = 5))
###############################
t8 <- PC3PC4_plots$plots[[5]]
xmldata <- simplified %>%
filter(sample_type==a) %>%
filter(guppied_date=="t8") %>%
group_split(component)
t8 +
xlab(paste0("PC3 (",get_var(find_PC3(xmldata)),"%)"))+
ylab(paste0("PC4 (",get_var(find_PC4(xmldata)),"%)"))
# PC3
grid.text(PC_down(find_PC3(xmldata)), x = unit(0.3, "npc"),
y = unit(0.1, "npc"),
gp = gpar(fontsize = 5))
grid.text(PC_up(find_PC3(xmldata)), x = unit(0.85, "npc"),
y = unit(0.1, "npc"),
gp = gpar(fontsize = 5))
# PC4
grid.text(PC_down(find_PC4(xmldata)), x = unit(0.1, "npc"),
y = unit(0.25, "npc"),
gp = gpar(fontsize = 5))
grid.text(PC_up(find_PC4(xmldata)), x = unit(0.1, "npc"),
y = unit(0.8, "npc"),
gp = gpar(fontsize = 5))
###############################
t9 <- PC3PC4_plots$plots[[6]]
xmldata <- simplified %>%
filter(sample_type==a) %>%
filter(guppied_date=="t9") %>%
group_split(component)
t9 +
xlab(paste0("PC3 (",get_var(find_PC3(xmldata)),"%)"))+
ylab(paste0("PC4 (",get_var(find_PC4(xmldata)),"%)"))
# PC3
grid.text(PC_down(find_PC3(xmldata)), x = unit(0.3, "npc"),
y = unit(0.1, "npc"),
gp = gpar(fontsize = 5))
grid.text(PC_up(find_PC3(xmldata)), x = unit(0.85, "npc"),
y = unit(0.1, "npc"),
gp = gpar(fontsize = 5))
# PC4
grid.text(PC_down(find_PC4(xmldata)), x = unit(0.1, "npc"),
y = unit(0.25, "npc"),
gp = gpar(fontsize = 5))
grid.text(PC_up(find_PC4(xmldata)), x = unit(0.1, "npc"),
y = unit(0.8, "npc"),
gp = gpar(fontsize = 5))
###############################
dev.off()
##############################
##############################
##############################
###########################################################################################
###########################################################################################
###########################################################################################
# Checking significance and plot based on significance:
###########################################################################################
###################################
###################################
# function 1. : takes dataframe, filters less than n observations, per component, per collection date, per cohort
myfun_pvalue_df_prep1 <- function(df1_here,n) {
# first, join the PCs to be in one columns, so you can easily apply the t.test function to one column only
a <- df1_here %>%
select(PC1,PC2,PC3,PC4,PC5,Cohort,collection_date,guppied_date,sample_type) %>%
pivot_longer(
cols = 1:5,
names_to = "component",
values_to = "value",
values_drop_na = FALSE
)
# look at distribution - filter out if less than n observations, per component, per collection date, per cohort
df1 <- setDT(a)[, .(Freq = .N), by = .(collection_date,Cohort,component)]
df1 <- df1 %>% filter(!Freq<n)
a <- merge(a,df1)
a <- a %>%
select(Cohort,collection_date,guppied_date,sample_type,component,value)
return(a)
}
###################################
###################################
# function 2. : takes dataframe, computes t.test of PC values between Cohorts (within same date,group)
myfun_pvalue_df_prep2 <- function(df2_here) {
# create an empty df to build on
df_pval <- data.frame(
group_2 = character(),
group_1 = character(),
p_value = numeric(),
which_PC = character(),
which_colldate = character()
)
a <- df2_here
# for each of the components (PC1 to PC5) ...
listcompos <- unique(a$component)
for (compo in listcompos) {
df <- a %>% filter(component==compo)
listcoldates <- unique(df$guppied_date)
for (colldate in listcoldates) {
z <- pairwise.t.test(df$value[df$guppied_date==colldate], df$Cohort[df$guppied_date==colldate], p.adjust = "none")$p.value
z <- as.data.frame(z)
z
z$group_2 <- rownames(z)
rownames(z) <- NULL
z <- z %>%
pivot_longer(
cols = -group_2,
names_to = "group_1",
values_to = "p_value",
values_drop_na = TRUE
)
z <- z %>% mutate(which_colldate = colldate,
which_PC = compo)
df_pval <- rbind(df_pval,z)
}
}
return(df_pval)
}
###################################
###################################
# function 3. : takes p-values, removes unnecessary comparisons
myfun_pvalues_filtering <- function(df_pval) {
# Final adjustments
df_pval <- df_pval %>%
# join the two groups for which the p-value has been computed
mutate(comparison=paste0(group_1,"_vs_",group_2)) %>%
select(p_value,which_colldate,which_PC,comparison,group_1,group_2)
# filtering to keep only meaningful comparisons
# to be kept:
meaningfulcomparisons <- c("Control_vs_ColiGuard", "ColiGuard_vs_Control",
"Control_vs_D-Scour", "D-Scour_vs_Control",
"Control_vs_Neomycin", "Neomycin_vs_Control",
"Neomycin_vs_Neomycin+D-Scour", "Neomycin+D-Scour_vs_Neomycin",
"Neomycin_vs_Neomycin+ColiGuard", "Neomycin+ColiGuard_vs_Neomycin")
# eliminate useless comparisons
df_pval <- df_pval[df_pval$comparison %in% meaningfulcomparisons,]
return(df_pval)
}
###################################
###################################
# binding all dataframes except the one where all samples (irrespective of dates) where guppied in one run
# DF_piggies_time,groupA,groupB,groupC,groupD,groupE,groupF,groupG
all <- rbind(DF_piggies_time,
groupA,
groupB,
groupC,
groupD,
groupE,
groupF,
groupG)
all$groupsplit <- paste0(all$sample_type,"_",all$guppied_date)
# splitting into multiple dataframes (by file name)
multi_DFs <- split( all , f = all$groupsplit )
# prep empty df to build on
significant <- data.frame(
group_1 = character(),
group_2 = character(),
p_value = numeric(),
which_colldate = character(),
which_PC = character(),
comparison = character(),
pval.adj = numeric(),
groupsplit = character(),
stringsAsFactors = FALSE
)
###################################
###################################
# runs single dataframe (one df : one guppy run) through functions; returns all p-values
for (singl_DF in multi_DFs) {
# function 1
a1 <- myfun_pvalue_df_prep1(singl_DF,2)
# function 2
a2 <- myfun_pvalue_df_prep2(a1)
# function 3
a3 <- myfun_pvalues_filtering(a2)
# convert to class dataframe
a4 <- as.data.frame(a3)
# assign name of dataframe to dataframe (useful for later rbinding)
a5 <- a4 %>%
mutate(groupsplit = singl_DF$groupsplit[1])
# rbind all
significant <- rbind(
significant,
a5)
}
###################################
###################################
significant$test <- "pairwise.t.test"
# save stats
# addWorksheet(wb, "guppy_pvalues")
# writeData(wb, sheet = "guppy_pvalues", significant, rowNames = FALSE)
fwrite(x=significant, file=paste0(stats_dir,"guppy_pvalues.csv"))
significant$test <- NULL
###################################
###################################
# Post-hoc correction:
final <- significant %>%
group_by(groupsplit) %>%
add_tally() %>%
mutate(threshold = 0.05/n) %>%
filter(p_value<threshold)
final
###################################
###################################
final$padj_method <- "Bonferroni"
# save stats
# addWorksheet(wb, "guppy_padj")
# writeData(wb, sheet = "guppy_padj", final, rowNames = FALSE)
fwrite(x=final, file=paste0(stats_dir,"guppy_padj.csv"))
###################################
###################################
final <- cSplit(final, "groupsplit","_")
colnames(final)[colnames(final)=="groupsplit_1"] <- "dataframe"
colnames(final)[colnames(final)=="groupsplit_2"] <- "guppied_date"
# dummy df to associate guppied_date with collection_date
dummy <- data.frame(guppied_date = as.character(c("t0","t2","t4","t6","t8","t9")),
collection_date = as.character(c("t0","t2","t4","t6","t8","t9")))
unique(final$guppied_date)
# adding collection_date to dataframe
df <- inner_join(final,dummy)
unique(df$collection_date)
# string replacement (as we haven't included DF_piggies (single guppy run),
# for coherence we need to specify that this data comes from DF_piggies_time (multiple guppy runs))
df$dataframe <- gsub("piggies","DF_piggies_time",df$dataframe)
############
# XML data extract
# taking all along except the guppy run with all the samples from all time points
unique(simplified$guppied_date)
simplified2 <- simplified %>%
filter(!guppied_date == "tALL")
simplified2 <- simplified2 %>%
filter(!guppied_date == "tNONE")
# now the only piggies are from the DF_piggies_time guppy runs
unique(simplified2$sample_type)
#simplified2$sample_type <- gsub("piggies","DF_piggies_time",simplified2$sample_type)
unique(simplified2$guppied_date)
unique(df$guppied_date)
###################################
###################################
mytheme <- theme(legend.position = "none",
axis.text.x=element_text(size=3),
axis.title.x=element_text(size=5),
axis.text.y=element_text(size=3),
axis.title.y=element_text(size=4),
plot.title = element_text(size = 6, face = "bold"))
# Plots only statistically significant observations,
# reporting xml data and dataframe (guppy run) it comes from
unique(df$collection_date)
mygrobs <- vector('list', nrow(df))
pdf(paste0(out_dir,"guppy_sign_cohorts.pdf"), onefile = TRUE)
for (A in rownames(df)) {
A <- as.numeric(A) # dataframes rownames must be taken as numeric
kk <- eval(as.name(paste(df$dataframe)))
kk$collection_date <- gsub("2017-01-31","t0",kk$collection_date)
kk$collection_date <- gsub("2017-02-07","t2",kk$collection_date)
kk$collection_date <- gsub("2017-02-14","t4",kk$collection_date)
kk$collection_date <- gsub("2017-02-21","t6",kk$collection_date)
kk$collection_date <- gsub("2017-02-28","t8",kk$collection_date)
kk$collection_date <- gsub("2017-03-03","t9",kk$collection_date)
# subsetting of original dataframe based on what is statistically significant (rows of df)
pp <- kk %>%
filter(collection_date==as.character(df$collection_date[A])) %>%
filter(sample_type==as.character(df$dataframe[A])) %>%
filter(Cohort==as.character(df$group_1[A])|Cohort==as.character(df$group_2[A])) %>%
select(PC1,PC2,PC3,PC4,PC5,Cohort,collection_date,guppied_date,sample_type) %>%
pivot_longer(
cols = 1:5,
names_to = "component",
values_to = "value",
values_drop_na = FALSE
) %>%
filter(component==as.name(paste(df$which_PC[A])))
pp$Cohort <- factor(pp$Cohort,
levels=c("Control",
"D-Scour",
"ColiGuard",
"Neomycin",
"Neomycin+D-Scour",
"Neomycin+ColiGuard"))
# save some parameters to report on plot
title1 <- unique(pp$guppied_date)
title2 <- unique(pp$sample_type)
PC_lab <- unique(pp$component)
# add xml data
# subsetting the xml data based on the significant observations dataframe
a <- df$dataframe[A]
b <- df$guppied_date[A]
c <- df$which_PC[A]
xmldata <- simplified2 %>%
filter(sample_type==a) %>%
filter(guppied_date==b) %>%
filter(component==c)
# build plot
p <- ggplot(pp, aes(x=value, fill=Cohort)) +
geom_histogram( color="#e9ecef", alpha=0.6, position = 'stack')+
ggtitle(paste0(title1)) +    # this way it contains df info: ggtitle(paste0(title1,"_",title2))
theme_bw()+
mytheme+
xlab(paste0(PC_lab," (",get_var(xmldata),"%)"))+
scale_fill_discrete(drop=FALSE)
g1 <- text_grob(paste0(PC_down(xmldata)),size=3,lineheight = 1)
g2 <- text_grob(paste0(PC_up(xmldata)),size=3,lineheight = 1)
lay <- rbind(c(1,1,1,1,1),
c(1,1,1,1,1),
c(2,2,2,3,3))
grid.arrange(p,g1,g2, layout_matrix = lay)
mygrobs[[A]]  <- grid.arrange(p,g1,g2, layout_matrix = lay)
}
dev.off()
# re-order
DF_piggies$Cohort <- factor(DF_piggies$Cohort,
levels=c("Control",
"D-Scour",
"ColiGuard",
"Neomycin",
"Neomycin+D-Scour",
"Neomycin+ColiGuard"))
DF_piggies <- DF_piggies[!is.na(DF_piggies$Cohort),]
# for legend only
pp <- ggplot(DF_piggies, aes(x=PC1, fill=Cohort)) +
geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity')+
theme_bw()+
mytheme+
theme(legend.position="right",
legend.title = element_text(size = 6),
legend.text = element_text(size = 4))+
scale_fill_discrete(drop=FALSE)
leg <- get_legend(pp)
# a selection of plots from the figure generated above
pdf(paste0(out_dir,"guppy_sign_cohorts_selection.pdf"))
lay <- rbind(c(1,2),
c(3,4),
c(5,6),
c(7,8))
grid.arrange(mygrobs[[10]]
,mygrobs[[2]],
mygrobs[[6]],
mygrobs[[8]],
mygrobs[[3]],
mygrobs[[4]],
mygrobs[[9]],
leg,
layout_matrix = lay)
dev.off()
##########################################################################################
##########################################################################################
##########################################################################################
##########################################################################################
complete <- read_csv(file = paste0(middle_dir,"guppy_xml_complete.df"))
############ VARIATION BEST EXPLAINED BY - DURING TIME - IN PIGGIES:
# "complete" comes from guppy_XML_process.R
simplified2 <- complete %>%
dplyr::select(sample_type, guppied_date,branch_width,var_explained,component,PC_position,taxa_simple) %>%
# taking all along except the guppy run with all the samples from all time points
filter(!guppied_date == "tALL")
# now the only piggies are from the DF_piggies_time guppy runs
simplified2$sample_type <- gsub("piggies","DF_piggies_time",simplified2$sample_type)
# branch_width * var_explained = importance
unique(simplified2$sample_type)
simplified2 <- simplified2 %>%
dplyr::mutate(importance = as.numeric(branch_width)*var_explained) %>%
filter(sample_type=="all"|sample_type=="groupA"|sample_type=="groupB") %>% # eventual selection of only one guppy run
select(guppied_date,taxa_simple,importance)
both <- simplified2 %>%
group_by(taxa_simple,guppied_date) %>%
dplyr::summarize(Sum_importance = sum(importance))
unique(both$taxa_simple) # 61 taxa
NROW(both)
both <- both[complete.cases(both), ] # remove NAs - necessary!
# normalize by date:
both <- both %>%
group_by(guppied_date) %>%
dplyr::mutate(Sum_importance=Sum_importance/sum(Sum_importance))
tail(both)
head(both)
both_wide <- both %>%
pivot_wider(names_from = guppied_date, values_from = Sum_importance) %>%
select(taxa_simple,t0,t2,t4,t6,t8,t9) %>%
dplyr::mutate_all(~replace(., is.na(.), 0))
both_wide <- as.data.frame(both_wide)
##############################
# put order (use taxize to order taxa based on evolutionary closeness)
#
# mytaxa <- both_wide[,1]
# mytaxa <- gsub("_"," ",mytaxa)
#
# uids <- get_uid(mytaxa)
#
# out <- classification(uids)
#
# out2 <- do.call(rbind.data.frame, out)
#
# out2$index <- rownames(out2)
#
# out2 <- cSplit(out2, "index",".")
# out2$rank <- NULL
# out2$id <- NULL
#
# out3 <- out2 %>%
#   spread(key = index_2, value = name)
#
# out3$index_1 <- NULL
# out3 <- as.data.frame(lapply(out3, function(y) gsub(" ", "__", y)))
#
# #remove rows where all NA
# out3 <- out3 %>% filter_all(any_vars(!is.na(.)))
#
# ind <- !is.na(out3)
# out3$taxa_simple <- tapply(out3[ind], row(out3)[ind], tail, 1)
#
# out3$taxa_simple<-toupper(out3$taxa_simple)
#
# out4 <- left_join(both_wide,out3,by= "taxa_simple")
# NROW(out4)
# head(out4)
#
# out5 <- out4 %>%
#   arrange(., X2,X3,X4,X5,X6,X7,X8,X9) %>%
#   select(taxa_simple,t0,t2,t4,t6,t8,t9)
# head(out5)
#
# out5 <- as.data.frame(out5)
#
##############################
##############################
# dates to timepoint conversion:
colnames(both_wide) <- c("taxa_simple","t0","t2","t4","t6","t8","t10")
out5 <- both_wide
# to matrix conversion
rownames(out5) <- out5[,1]
out5[,1] <- NULL
out_m <- as.matrix(out5)
##############################
# normalization by date already done above
# remove cells with low rowSums
out_m <- as.matrix(out_m[rowSums(out_m)>0.01,])
time_beta_plot <- pheatmap(out_m, display_numbers = T, angle_col = 0,
cluster_rows = T, cluster_cols = F, fontsize_number = 8,
fontsize_row = 8)
pdf(paste0(out_dir,"time_beta_heatmap.pdf"))
time_beta_plot
dev.off()
##########################################################################################
##########################################################################################
##########################################################################################
##########################################################################################
# #save stats in workbook
# saveWorkbook(wb, paste0(out_dir_git,"stats.xlsx"), overwrite=TRUE)
